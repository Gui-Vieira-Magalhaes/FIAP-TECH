import streamlit as st
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="POSTECH - DTAT - Datathon - Fase 5", layout="wide")

# Carregar os dados do CSV
def carregar_dados():
    file_path = "PEDE_PASSOS_DATASET_FIAP.csv"  # Atualizar conforme necessÃ¡rio
    df = pd.read_csv(file_path, delimiter=";")
    return df

df = carregar_dados()

# Selecionar as colunas relevantes para a modelagem
features = [
    "INDE_2022", "IEG_2022", "IPV_2022", "IDA_2022", "NOTA_MAT_2022", "NOTA_PORT_2022",
    "CG_2022", "CT_2022", "QTD_AVAL_2022", "FASE_2022"
]
target = "IAA_2022"

# Renomear colunas para remover o sufixo "_2022"
feature_names = {col: col.replace("_2022", "") for col in features}
df = df.rename(columns=feature_names)

# Remover valores nulos
df = df[list(feature_names.values()) + [target]].dropna()
X = df[list(feature_names.values())]
y = df[target]

# Normalizar os dados
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Treinar Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Treinar Rede Neural
nn_model = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=42)
nn_model.fit(X_train, y_train)

if st.sidebar.radio("NavegaÃ§Ã£o", ["ğŸ† Conceitos", "ğŸ“Š PrediÃ§Ã£o do IAA"]) == "ğŸ† Conceitos":
    st.markdown("# ğŸ† POSTECH - DTAT - Datathon - Fase 5")
    st.markdown("### ğŸ“Œ Integrantes do Grupo: FÃ¡bio Cervantes Lima, Guilherme Vieira MagalhÃ£es")
    st.write("### â„¹ï¸ O que Ã© o IAA?")
    st.write("O Ãndice de Aproveitamento AcadÃªmico (IAA) mede o desempenho acadÃªmico dos alunos levando em consideraÃ§Ã£o notas, participaÃ§Ã£o e engajamento. Essa mÃ©trica ajuda a avaliar a evoluÃ§Ã£o dos estudantes ao longo do tempo e pode ser utilizada para prever o desempenho futuro, possibilitando intervenÃ§Ãµes educacionais estratÃ©gicas.")
    
    # AvaliaÃ§Ã£o dos modelos
    rf_pred = rf_model.predict(X_test)
    nn_pred = nn_model.predict(X_test)
    
    rf_mae = mean_absolute_error(y_test, rf_pred)
    rf_rmse = mean_squared_error(y_test, rf_pred) ** 0.5
    rf_r2 = r2_score(y_test, rf_pred)
    
    nn_mae = mean_absolute_error(y_test, nn_pred)
    nn_rmse = mean_squared_error(y_test, nn_pred) ** 0.5
    nn_r2 = r2_score(y_test, nn_pred)
    
    st.write("### ğŸ“Š ComparaÃ§Ã£o de Modelos")
    st.write(f"#### Random Forest")
    st.write(f"- **Erro Absoluto MÃ©dio (MAE):** {rf_mae:.2f}")
    st.write(f"- **Raiz do Erro QuadrÃ¡tico MÃ©dio (RMSE):** {rf_rmse:.2f}")
    st.write(f"- **Coeficiente de DeterminaÃ§Ã£o (RÂ²):** {rf_r2:.2f}")
    
    st.write(f"#### Redes Neurais")
    st.write(f"- **Erro Absoluto MÃ©dio (MAE):** {nn_mae:.2f}")
    st.write(f"- **Raiz do Erro QuadrÃ¡tico MÃ©dio (RMSE):** {nn_rmse:.2f}")
    st.write(f"- **Coeficiente de DeterminaÃ§Ã£o (RÂ²):** {nn_r2:.2f}")
    
    st.write("### ğŸ“Š Escolha do Modelo Preditivo")
    st.write("O **Random Forest** foi escolhido devido Ã  sua robustez em prever valores numÃ©ricos, resistÃªncia a overfitting e boa interpretabilidade. Por outro lado, **Redes Neurais** podem capturar padrÃµes mais complexos, mas exigem maior poder computacional e sÃ£o mais difÃ­ceis de interpretar. Observamos que, para nosso conjunto de dados, o **Random Forest teve melhor aderÃªncia**.")
    
    # Adicionar grÃ¡ficos relevantes
    st.write("### ğŸ“Š VisualizaÃ§Ã£o de Dados")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5, ax=ax)
    st.pyplot(fig)

else:
    st.markdown("# ğŸ† POSTECH - DTAT - Datathon - Fase 5")
    st.markdown("### ğŸ“Œ Integrantes do Grupo: FÃ¡bio Cervantes Lima, Guilherme Vieira MagalhÃ£es")
    
    st.write("## ğŸ¯ ExplicaÃ§Ã£o das VariÃ¡veis")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write("### VariÃ¡veis AcadÃªmicas")
        st.write("- **INDE**: Ãndice de Desenvolvimento Educacional")
        st.write("- **IEG**: Ãndice de Engajamento Geral")
        st.write("- **IPV**: Ãndice de Ponto de Virada")
    with col2:
        st.write("### Notas e AvaliaÃ§Ãµes")
        st.write("- **IDA**: Ãndice de Desenvolvimento AcadÃªmico")
        st.write("- **NOTA_MAT**: Nota de MatemÃ¡tica")
        st.write("- **NOTA_PORT**: Nota de PortuguÃªs")
    with col3:
        st.write("### Outras VariÃ¡veis")
        st.write("- **CG**: Carga de Grau")
        st.write("- **CT**: Carga Total")
        st.write("- **QTD_AVAL**: Quantidade de AvaliaÃ§Ãµes")
        st.write("- **FASE**: Fase AcadÃªmica")
    
    st.write("## ğŸ¯ Insira os dados do aluno para prever o IAA")
    col1, col2, col3 = st.columns(3)
    dados_usuario = []
    for i, feature in enumerate(feature_names.values()):
        with [col1, col2, col3][i % 3]:
            valor = st.number_input(f"{feature}", min_value=0.0, max_value=10.0, step=0.1, value=min(10.0, max(0.0, df[feature].mean())))
            dados_usuario.append(valor)
    
    if st.button("ğŸ” Prever IAA"):
        dados_usuario_np = np.array(dados_usuario).reshape(1, -1)
        dados_usuario_scaled = scaler.transform(dados_usuario_np)
        rf_previsao = rf_model.predict(dados_usuario_scaled)[0]
        nn_previsao = nn_model.predict(dados_usuario_scaled)[0]
        
        st.success(f"ğŸ¯ PrevisÃ£o do IAA com Random Forest: {rf_previsao:.2f}")
        st.success(f"ğŸ¯ PrevisÃ£o do IAA com Redes Neurais: {nn_previsao:.2f}")
        st.write("ğŸ“Œ **Baseado na avaliaÃ§Ã£o dos modelos, a prediÃ§Ã£o do Random Forest Ã© a mais aderente ao conjunto de dados.**")


